{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatage pour tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## formatage des fichiers en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion de product_links.json en CSV...\n",
      "Fichier CSV généré avec succès : C:\\TOUS_MES_FICHIERS\\ProjetPython\\TravauxTechniques\\4formatage_pour_tableau\\product_links.csv\n",
      "Conversion de data_fusion_cleaned.json en CSV...\n",
      "Fichiers CSV générés avec succès : C:\\TOUS_MES_FICHIERS\\ProjetPython\\TravauxTechniques\\4formatage_pour_tableau\\data_fusion_products.csv, C:\\TOUS_MES_FICHIERS\\ProjetPython\\TravauxTechniques\\4formatage_pour_tableau\\data_fusion_comments.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Chemins des fichiers JSON et CSV\n",
    "product_links_json = r\"C:\\TOUS_MES_FICHIERS\\ProjetPython\\TravauxTechniques\\1scraping\\datasets\\products\\product_links.json\"\n",
    "data_fusion_json = r\"C:\\TOUS_MES_FICHIERS\\ProjetPython\\TravauxTechniques\\2traitement\\datasets\\data_fusion_cleaned.json\"\n",
    "product_links_csv = r\"C:\\TOUS_MES_FICHIERS\\ProjetPython\\TravauxTechniques\\4formatage_pour_tableau\\product_links.csv\"\n",
    "data_fusion_products_csv = r\"C:\\TOUS_MES_FICHIERS\\ProjetPython\\TravauxTechniques\\4formatage_pour_tableau\\data_fusion_products.csv\"\n",
    "data_fusion_comments_csv = r\"C:\\TOUS_MES_FICHIERS\\ProjetPython\\TravauxTechniques\\4formatage_pour_tableau\\data_fusion_comments.csv\"\n",
    "\n",
    "def extraire_categorie(url):\n",
    "    \"\"\"\n",
    "    Extraire le nom lisible de la catégorie depuis une URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL de la catégorie.\n",
    "\n",
    "    Returns:\n",
    "        str: Nom lisible de la catégorie.\n",
    "    \"\"\"\n",
    "    return urlparse(url).path.strip(\"/\").split(\"/\")[-1].replace(\"-\", \" \").capitalize()\n",
    "\n",
    "def convertir_product_links_en_csv(product_links_json, output_csv):\n",
    "    \"\"\"\n",
    "    Convertir le fichier JSON des liens produits en un fichier CSV.\n",
    "\n",
    "    Args:\n",
    "        product_links_json (str): Chemin du fichier JSON des liens produits.\n",
    "        output_csv (str): Chemin du fichier CSV de sortie pour les liens produits.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Conversion de product_links.json en CSV...\")\n",
    "        with open(product_links_json, \"r\", encoding=\"utf-8\") as file:\n",
    "            product_links_data = json.load(file)\n",
    "\n",
    "        with open(output_csv, \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
    "            fieldnames = [\"Categorie\", \"Lien_Produit\", \"Nom_Produit\", \"Prix\", \"Avis\"]\n",
    "            writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            for categorie, produits in product_links_data.items():\n",
    "                categorie_nom = extraire_categorie(categorie)\n",
    "                for produit in produits:\n",
    "                    writer.writerow({\n",
    "                        \"Categorie\": categorie_nom,\n",
    "                        \"Lien_Produit\": produit.get(\"link\"),\n",
    "                        \"Nom_Produit\": produit.get(\"name\"),\n",
    "                        \"Prix\": produit.get(\"price\"),\n",
    "                        \"Avis\": produit.get(\"reviews\"),\n",
    "                    })\n",
    "\n",
    "        print(f\"Fichier CSV généré avec succès : {output_csv}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite lors de la conversion de product_links : {e}\")\n",
    "\n",
    "def convertir_data_fusion_en_csv(data_fusion_json, product_links_json, products_output_csv, comments_output_csv):\n",
    "    \"\"\"\n",
    "    Convertir le fichier JSON des données fusionnées en deux fichiers CSV :\n",
    "    - Un pour les produits.\n",
    "    - Un pour les commentaires.\n",
    "\n",
    "    Args:\n",
    "        data_fusion_json (str): Chemin du fichier JSON des données fusionnées.\n",
    "        product_links_json (str): Chemin du fichier JSON des liens produits pour associer les catégories.\n",
    "        products_output_csv (str): Chemin du fichier CSV de sortie pour les produits.\n",
    "        comments_output_csv (str): Chemin du fichier CSV de sortie pour les commentaires.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Conversion de data_fusion_cleaned.json en CSV...\")\n",
    "        # Charger les données JSON\n",
    "        with open(data_fusion_json, \"r\", encoding=\"utf-8\") as file:\n",
    "            data_fusion_data = json.load(file)\n",
    "\n",
    "        with open(product_links_json, \"r\", encoding=\"utf-8\") as file:\n",
    "            product_links_data = json.load(file)\n",
    "\n",
    "        # Associer les produits aux catégories\n",
    "        produit_categorie = {}\n",
    "        for categorie, produits in product_links_data.items():\n",
    "            for produit in produits:\n",
    "                produit_categorie[produit[\"link\"]] = extraire_categorie(categorie)\n",
    "\n",
    "        # Écrire les données produits\n",
    "        with open(products_output_csv, \"w\", encoding=\"utf-8\", newline=\"\") as products_file:\n",
    "            products_fieldnames = [\n",
    "                \"Categorie\", \"Lien_Produit\", \"Nom_Produit\", \"Prix\", \"Note_Moyenne\", \"Nombre_Avis\", \"Nombre_Commentaires\"\n",
    "            ]\n",
    "            products_writer = csv.DictWriter(products_file, fieldnames=products_fieldnames)\n",
    "            products_writer.writeheader()\n",
    "\n",
    "            for produit in data_fusion_data:\n",
    "                categorie = produit_categorie.get(produit[\"link\"], \"Non catégorisé\")\n",
    "                products_writer.writerow({\n",
    "                    \"Categorie\": categorie,\n",
    "                    \"Lien_Produit\": produit.get(\"link\"),\n",
    "                    \"Nom_Produit\": produit.get(\"name\"),\n",
    "                    \"Prix\": produit.get(\"price\"),\n",
    "                    \"Note_Moyenne\": produit.get(\"average_rating\"),\n",
    "                    \"Nombre_Avis\": produit.get(\"total_reviews\"),\n",
    "                    \"Nombre_Commentaires\": len(produit.get(\"comments\", [])),\n",
    "                })\n",
    "\n",
    "        # Écrire les données commentaires\n",
    "        with open(comments_output_csv, \"w\", encoding=\"utf-8\", newline=\"\") as comments_file:\n",
    "            comments_fieldnames = [\n",
    "                \"Categorie\", \"Lien_Produit\", \"Nom_Produit\", \"Titre_Commentaire\", \"Commentaire\",\n",
    "                \"Titre_Commentaire_Processe\", \"Commentaire_Processe\", \"Contient_Contraste\"\n",
    "            ]\n",
    "            comments_writer = csv.DictWriter(comments_file, fieldnames=comments_fieldnames)\n",
    "            comments_writer.writeheader()\n",
    "\n",
    "            for produit in data_fusion_data:\n",
    "                categorie = produit_categorie.get(produit[\"link\"], \"Non catégorisé\")\n",
    "                for commentaire in produit.get(\"comments\", []):\n",
    "                    comments_writer.writerow({\n",
    "                        \"Categorie\": categorie,\n",
    "                        \"Lien_Produit\": produit.get(\"link\"),\n",
    "                        \"Nom_Produit\": produit.get(\"name\"),\n",
    "                        \"Titre_Commentaire\": commentaire.get(\"title\"),\n",
    "                        \"Commentaire\": commentaire.get(\"content\"),\n",
    "                        \"Titre_Commentaire_Processe\": commentaire.get(\"processed_title\"),\n",
    "                        \"Commentaire_Processe\": commentaire.get(\"processed_content\"),\n",
    "                        \"Contient_Contraste\": commentaire.get(\"contains_contrast\"),\n",
    "                    })\n",
    "\n",
    "        print(f\"Fichiers CSV générés avec succès : {products_output_csv}, {comments_output_csv}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite lors de la conversion de data_fusion_cleaned : {e}\")\n",
    "\n",
    "# Exécution des conversions\n",
    "convertir_product_links_en_csv(product_links_json, product_links_csv)\n",
    "convertir_data_fusion_en_csv(data_fusion_json, product_links_json, data_fusion_products_csv, data_fusion_comments_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier CSV généré avec succès : unigrammes_par_categorie.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Chemins des fichiers\n",
    "input_file = r\"data_fusion_comments.csv\"  # Fichier source\n",
    "output_file = r\"unigrammes_par_categorie.csv\"  # Fichier de sortie\n",
    "\n",
    "# Charger les données\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Combiner les colonnes de commentaires traités\n",
    "data[\"Combined_Comments\"] = data[\"Titre_Commentaire_Processe\"].fillna(\"\") + \" \" + data[\"Commentaire_Processe\"].fillna(\"\")\n",
    "\n",
    "# Groupement par catégorie et extraction des mots\n",
    "unigram_data = []\n",
    "\n",
    "for categorie, group in data.groupby(\"Categorie\"):\n",
    "    words = []\n",
    "    for comment in group[\"Combined_Comments\"]:\n",
    "        words.extend(comment.split())  # Diviser les mots dans chaque commentaire\n",
    "    word_counts = Counter(words)  # Compter les mots pour chaque catégorie\n",
    "    for word, frequency in word_counts.items():\n",
    "        unigram_data.append({\"Categorie\": categorie, \"Word\": word, \"Frequency\": frequency})\n",
    "\n",
    "# Créer un DataFrame et sauvegarder dans un fichier CSV\n",
    "unigram_df = pd.DataFrame(unigram_data)\n",
    "unigram_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Fichier CSV généré avec succès : {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier CSV généré avec succès : bigrams_par_categorie.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import tee\n",
    "\n",
    "# Chemins des fichiers\n",
    "input_file = r\"data_fusion_comments.csv\"  # Fichier source\n",
    "output_file = r\"bigrams_par_categorie.csv\"  # Fichier de sortie\n",
    "\n",
    "def generate_bigrams(words):\n",
    "    \"\"\"\n",
    "    Générer des bigrammes à partir d'une liste de mots.\n",
    "\n",
    "    Args:\n",
    "        words (list): Liste de mots.\n",
    "\n",
    "    Returns:\n",
    "        list: Liste de tuples contenant les bigrammes.\n",
    "    \"\"\"\n",
    "    a, b = tee(words)\n",
    "    next(b, None)\n",
    "    return list(zip(a, b))\n",
    "\n",
    "# Charger les données\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Combiner les colonnes de commentaires traités\n",
    "data[\"Combined_Comments\"] = data[\"Titre_Commentaire_Processe\"].fillna(\"\") + \" \" + data[\"Commentaire_Processe\"].fillna(\"\")\n",
    "\n",
    "# Groupement par catégorie et extraction des bigrammes\n",
    "bigram_data = []\n",
    "\n",
    "for categorie, group in data.groupby(\"Categorie\"):\n",
    "    bigrams = []\n",
    "    for comment in group[\"Combined_Comments\"]:\n",
    "        words = comment.split()  # Diviser les mots dans chaque commentaire\n",
    "        bigrams.extend(generate_bigrams(words))  # Générer les bigrammes\n",
    "    bigram_counts = Counter(bigrams)  # Compter les bigrammes pour chaque catégorie\n",
    "    for bigram, frequency in bigram_counts.items():\n",
    "        bigram_data.append({\"Categorie\": categorie, \"Bigram\": \" \".join(bigram), \"Frequency\": frequency})\n",
    "\n",
    "# Créer un DataFrame et sauvegarder dans un fichier CSV\n",
    "bigram_df = pd.DataFrame(bigram_data)\n",
    "bigram_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Fichier CSV généré avec succès : {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
